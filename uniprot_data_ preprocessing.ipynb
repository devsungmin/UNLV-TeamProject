{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 4558: expected 9 fields, saw 13\\nSkipping line 16322: expected 9 fields, saw 14\\nSkipping line 32858: expected 9 fields, saw 13\\nSkipping line 46666: expected 9 fields, saw 15\\nSkipping line 58186: expected 9 fields, saw 15\\n'\n",
      "b'Skipping line 75855: expected 9 fields, saw 11\\nSkipping line 80704: expected 9 fields, saw 13\\nSkipping line 93878: expected 9 fields, saw 11\\nSkipping line 104584: expected 9 fields, saw 15\\nSkipping line 111801: expected 9 fields, saw 13\\nSkipping line 128096: expected 9 fields, saw 15\\n'\n",
      "b'Skipping line 137240: expected 9 fields, saw 11\\nSkipping line 146430: expected 9 fields, saw 14\\nSkipping line 153941: expected 9 fields, saw 15\\nSkipping line 164294: expected 9 fields, saw 11\\nSkipping line 172291: expected 9 fields, saw 15\\nSkipping line 189329: expected 9 fields, saw 16\\n'\n",
      "b'Skipping line 205588: expected 9 fields, saw 13\\nSkipping line 226578: expected 9 fields, saw 15\\nSkipping line 234622: expected 9 fields, saw 13\\nSkipping line 242963: expected 9 fields, saw 13\\nSkipping line 255594: expected 9 fields, saw 17\\n'\n",
      "b'Skipping line 267332: expected 9 fields, saw 17\\nSkipping line 324825: expected 9 fields, saw 13\\n'\n",
      "b'Skipping line 345150: expected 9 fields, saw 16\\nSkipping line 362255: expected 9 fields, saw 15\\nSkipping line 383135: expected 9 fields, saw 15\\n'\n",
      "b'Skipping line 402833: expected 9 fields, saw 13\\nSkipping line 424657: expected 9 fields, saw 11\\nSkipping line 432972: expected 9 fields, saw 13\\n'\n",
      "b'Skipping line 462139: expected 9 fields, saw 13\\nSkipping line 498792: expected 9 fields, saw 17\\n'\n",
      "b'Skipping line 525508: expected 9 fields, saw 13\\nSkipping line 562385: expected 9 fields, saw 13\\nSkipping line 583599: expected 9 fields, saw 13\\n'\n",
      "b'Skipping line 592809: expected 9 fields, saw 13\\nSkipping line 621455: expected 9 fields, saw 13\\nSkipping line 643530: expected 9 fields, saw 15\\n'\n",
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:3051: DtypeWarning: Columns (6,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "seq_data = pd.read_csv(\"uniprot_sprot_bacteria_J.csv\",error_bad_lines=False)\n",
    "seq_data = seq_data.drop(seq_data.iloc[:,1:8],axis=1)\n",
    "seq_id= seq_data.drop('SEQ',axis=1)\n",
    "seq_num= seq_data.drop('ID',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(fasta_file, temp_file):\n",
    "    l = 1000\n",
    "    fp = open(temp_file, 'w')\n",
    "    input_handle = open(fasta_file, \"r\")\n",
    "    for seq_record in SeqIO.parse(input_handle, \"fasta\"):   \n",
    "        seq_id = seq_record.id\n",
    "        seq = seq_record.seq\n",
    "        if len(seq) <= 1000:\n",
    "            fp.write('>%s\\n'%(seq_id))\n",
    "            fp.write('%s\\n'%(seq.strip()))\n",
    "        else:\n",
    "            for i in range(0, len(seq)-l+1, 100):\n",
    "                new_seq_id = '%s_SEPARATED_SEQUENCE_(%s_%s)' % (seq_id, i+1, i+l+1)\n",
    "                new_seq = seq[i:i+l]\n",
    "                fp.write('>%s\\n'%(new_seq_id))\n",
    "                fp.write('%s\\n'%(new_seq))\n",
    "    \n",
    "    input_handle.close()\n",
    "    fp.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_aa(seq):\n",
    "    fill_aa_cnt = 1000 - len(seq)\n",
    "    add_aa_seq = '_' * fill_aa_cnt\n",
    "    new_seq = seq + add_aa_seq\n",
    "    return new_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_info():\n",
    "    aa_list = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', 'X', '_']\n",
    "    aa_score_info = {}\n",
    "    for aa in aa_list:\n",
    "        for aa2 in aa_list:\n",
    "            if aa == aa2:\n",
    "                aa_score_info[(aa, aa2)] = 1.0\n",
    "                aa_score_info[(aa2, aa)] = 1.0\n",
    "            else:\n",
    "                aa_score_info[(aa, aa2)] = 0.0\n",
    "                aa_score_info[(aa2, aa)] = 0.0\n",
    "    return aa_score_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(seq, aa_score_info):\n",
    "    data = np.zeros((1000, 21), dtype=np.float32)\n",
    "    aa_list = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', 'X']\n",
    "    for i, aa in enumerate(seq):\n",
    "        for j, aa2 in enumerate(aa_list):\n",
    "            data[i, j] = aa_score_info[aa, aa2]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_hot_encoding(fasta_file, temp_file):\n",
    "    aa_score_info = score_info()\n",
    "    fp = open(temp_file, 'w')\n",
    "    feature_names = ['Feature%s'%(i) for i in range(1, 21001)] \n",
    "    \n",
    "    fp.write('%s\\n'%(','.join(['ID']+feature_names)))\n",
    "    \n",
    "    #input_handle = open(fasta_file, \"r\")\n",
    "    input_handle = seq_num\n",
    "    for seq_record in input_handle : #in SeqIO.parse(input_handle, \"fasta\"):   \n",
    "        try:\n",
    "            seq_id = seq_record.ID\n",
    "            seq = seq_record.SEQ\n",
    "            if len(seq) >= 10 and len(seq) <= 1000:\n",
    "                if len(seq) < 1000:\n",
    "                    seq = fill_aa(seq)\n",
    "                encoded_vector = one_hot_encoding(seq, aa_score_info)\n",
    "                flatten_encoded_vector = encoded_vector.flatten()\n",
    "                flatten_encoded_vector_str = [str(each_val) for each_val in flatten_encoded_vector]\n",
    "                fp.write('%s\\n'%(','.join([seq_id]+flatten_encoded_vector_str)))\n",
    "        except:\n",
    "            pass\n",
    "    #input_handle.close()\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_target_ec(df, output_file, DeepEC_model):\n",
    "    seq_ids = list(df.index)\n",
    "    X_temp = df.values\n",
    "    new_X = []\n",
    "    for i in range(len(X_temp)):\n",
    "        temp = np.reshape(X_temp[i], (1000, 21))\n",
    "        new_X.append(temp)\n",
    "    \n",
    "    X = np.asarray(new_X)\n",
    "    X = X.reshape(X.shape[0], 1000, 21, 1)\n",
    "    \n",
    "    model = load_model(DeepEC_model)\n",
    "    \n",
    "    y_predicted = model.predict(X)\n",
    "    enzyme_list = []\n",
    "    with open(output_file, 'w') as fp:\n",
    "        fp.write('Query ID\\tPredicted class\\tDNN activity\\n')\n",
    "        for i in range(len(y_predicted)): \n",
    "            socre = y_predicted[i][1]\n",
    "            if y_predicted[i][1] > 0.5:\n",
    "                enzyme_list.append(seq_ids[i])\n",
    "                fp.write('%s\\t%s\\t%s\\n'%(seq_ids[i], 'Target', socre))\n",
    "            else:\n",
    "                fp.write('%s\\t%s\\t%s\\n'%(seq_ids[i], 'Non-target', 1-socre))\n",
    "    return enzyme_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_enzyme(df, output_file, DeepEC_model):\n",
    "    seq_ids = list(df.index)\n",
    "    X_temp = df.values\n",
    "    new_X = []\n",
    "    for i in range(len(X_temp)):\n",
    "        temp = np.reshape(X_temp[i], (1000, 21))\n",
    "        new_X.append(temp)\n",
    "    \n",
    "    X = np.asarray(new_X)\n",
    "    X = X.reshape(X.shape[0], 1000, 21, 1)\n",
    "    \n",
    "    model = load_model(DeepEC_model)\n",
    "    \n",
    "    y_predicted = model.predict(X)\n",
    "    enzyme_list = []\n",
    "    with open(output_file, 'w') as fp:\n",
    "        fp.write('Query ID\\tPredicted class\\tDNN activity\\n')\n",
    "        for i in range(len(y_predicted)): \n",
    "            socre = y_predicted[i][1]\n",
    "            if y_predicted[i][1] > 0.5:\n",
    "                enzyme_list.append(seq_ids[i])\n",
    "                fp.write('%s\\t%s\\t%s\\n'%(seq_ids[i], 'Enzyme', socre))\n",
    "            else:\n",
    "                fp.write('%s\\t%s\\t%s\\n'%(seq_ids[i], 'Non-enzyme', 1-socre))\n",
    "    return enzyme_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ec(df, output_file, DeepEC_model, MultiLabelBinarizer, threshold=0.5):\n",
    "    if (sys.version_info > (3, 0)):\n",
    "        import _pickle as cPickle\n",
    "    else:\n",
    "        import cPickle\n",
    "    \n",
    "    seq_ids = list(df.index)\n",
    "    X_temp = df.values\n",
    "    new_X = []\n",
    "    for i in range(len(X_temp)):\n",
    "        temp = np.reshape(X_temp[i], (1000, 21))\n",
    "        new_X.append(temp)\n",
    "    \n",
    "    X = np.asarray(new_X)\n",
    "    X = X.reshape(X.shape[0], 1000, 21, 1)\n",
    "    \n",
    "    with open(MultiLabelBinarizer, 'rb') as fid:\n",
    "        lb = cPickle.load(fid)\n",
    "    \n",
    "    model = load_model(DeepEC_model)\n",
    "    \n",
    "    y_predicted = model.predict(X)\n",
    "    original_y_predicted = copy.deepcopy(y_predicted)\n",
    "    \n",
    "    y_predicted[y_predicted >= threshold] = 1\n",
    "    y_predicted[y_predicted <threshold] = 0\n",
    "\n",
    "    y_predicted_results = lb.inverse_transform(y_predicted) \n",
    "\n",
    "    with open(output_file, 'w') as fp:\n",
    "        fp.write('Query ID\\tPredicted EC number\\tDNN activity\\n')\n",
    "        for i in range(len(y_predicted)): \n",
    "            each_y_predicted = copy.deepcopy(y_predicted[i])\n",
    "            predicted_ddi_score = original_y_predicted[i]\n",
    "            target_index = np.flatnonzero(each_y_predicted == 1)\n",
    "            if len(target_index) > 0:\n",
    "                for each_idx in target_index:\n",
    "                    each_y_predicted = copy.deepcopy(y_predicted[i])\n",
    "                    each_y_predicted[:] = 0\n",
    "                    each_y_predicted[each_idx] = 1\n",
    "\n",
    "                    each_y_predicted = np.array([list(each_y_predicted)])\n",
    "                    y_transformed = lb.inverse_transform(each_y_predicted) \n",
    "\n",
    "                    score = predicted_ddi_score[each_idx]\n",
    "                    ec_number = y_transformed[0][0]\n",
    "                    fp.write('%s\\t%s\\t%s\\n'%(seq_ids[i], ec_number, score))\n",
    "            \n",
    "            else:\n",
    "                fp.write('%s\\t%s\\t%s\\n'%( seq_ids[i], 'EC number not predicted', 'N/A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_file=\"uniprot_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size=len(seq_id)\n",
    "seq_n=np.array(seq_data)\n",
    "seq_i=np.array(seq_id)\n",
    "aa_score_info = score_info()\n",
    "fp = open(temp_file, 'w')\n",
    "feature_names = ['Feature%s'%(i) for i in range(1, 21001)]     \n",
    "fp.write('%s\\n'%(','.join(['ID']+feature_names)))\n",
    "\n",
    "for i in range (data_size) :\n",
    "    try:\n",
    "        seq_id = \"\".join(map(str,seq_i[i]))\n",
    "        seq = \"\".join(map(str,seq_n[i]))\n",
    "    \n",
    "        if len(seq) >= 10 and len(seq) <= 1000:\n",
    "            if len(seq) < 1000:\n",
    "                seq = fill_aa(seq)\n",
    "            encoded_vector = one_hot_encoding(seq, aa_score_info)\n",
    "            #print(encoded_vector)\n",
    "            flatten_encoded_vector = encoded_vector.flatten()\n",
    "            flatten_encoded_vector_str = [str(each_val) for each_val in flatten_encoded_vector]\n",
    "            fp.write('%s\\n'%(','.join([seq_id]+flatten_encoded_vector_str)))\n",
    "    except:\n",
    "        pass\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
